{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Synthetic Sitelle Data\n",
    "\n",
    "In this notebook, we will demonstrate how to build a set of synthetic data using the LUCI package. Please note that this requires LUCI which can be installed via https://github.com/crhea93/LUCI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '/path/to/LUCI/')\n",
    "from LuciBase import Luci\n",
    "from LUCI.LuciSim import Spectrum\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Directory \n",
    "output_dir = '/your/path/here/'  # Include trailing /\n",
    "# Set observation parameters\n",
    "step = 2943  # Step Number -- don't change\n",
    "order = 8  # Order number -- don't change\n",
    "resolution = 5000  # Maximum resolution\n",
    "vel_num = 2000  # Number of Velocity Values Sampled\n",
    "broad_num = 100  # Number of Broadening Values Sampled\n",
    "theta_num = 100  # Number of Theta Values Sampled\n",
    "num_syn = 1000  # Number of Synthetic Spectra \n",
    "SNR = 50  # Define SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample velocity\n",
    "vel_ = np.random.uniform(-200,200,vel_num)\n",
    "# Sample broadening\n",
    "broad_ = np.random.uniform(0,50,broad_num)\n",
    "# Same resolution\n",
    "res_ = np.random.uniform(resolution-200, resolution, 200)  # Since the resolution can vary 200 over the field from the max..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to get our emission lines of interest\n",
    "lines = ['Halpha', 'NII6583', 'NII6548', 'SII6716', 'SII6731']\n",
    "# Set fitting function\n",
    "fit_function = 'sincgauss'\n",
    "# Set filter\n",
    "filter_ = 'SN3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must alo get our flux values from 3mdb\n",
    "# First we load in the parameters needed to login to the sql database\n",
    "\n",
    "#!!!! TO RUN THIS CODE YOU MUST FILL IN THE MdB variables   !!!!\n",
    "#!!!! TO ACCESS THESE GO TO https://sites.google.com/site/mexicanmillionmodels/ !!!!\n",
    "#!!!! AND ASK TO JOIN THE GOOGLE GROUP !!!!\n",
    "\n",
    "MdB_HOST=''\n",
    "MdB_USER=''\n",
    "MdB_PASSWD=''\n",
    "MdB_PORT=''\n",
    "MdB_DBs=''\n",
    "MdB_DBp=''\n",
    "MdB_DB_17=''\n",
    "# Now we connect to the database\n",
    "co = pymysql.connect(host=MdB_HOST, db=MdB_DB_17, user=MdB_USER, passwd=MdB_PASSWD)\n",
    "# Now we get the lines we want\n",
    "ampls = pd.read_sql(\"select H__1_656281A as h1, N__2_654805A as n1, N__2_658345A as n2, \\\n",
    "                  S__2_673082A  as s1, S__2_671644A as s2,   \\\n",
    "                  com1 as U, com2 as gf, com4 as ab \\\n",
    "                  from tab_17 \\\n",
    "                  where ref = 'BOND'\"\n",
    "                    , con=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now filter out values that are non representative of our SIGNALS sample\n",
    "filter1 = ampls['U'] == 'lU_mean = -2.5'\n",
    "filter2 = ampls['U'] == 'lU_mean = -3.0'\n",
    "filter3 = ampls['U'] == 'lU_mean = -3.5'\n",
    "filter4 = ampls['gf'] == 'fr = 3.0'\n",
    "ampls_filter = ampls.where(filter1 | filter2 | filter3 & filter4).dropna()\n",
    "ampls_filter = ampls_filter.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now can model the lines. For the moment, we will assume all lines have the same velocity and broadening\n",
    "# Do this for randomized combinations of vel_ and broad_\n",
    "for spec_ct in range(num_syn):\n",
    "    pick_new = True\n",
    "    # Randomly select velocity and broadening parameter and theta\n",
    "    velocity = random.choice(vel_)\n",
    "    broadening = random.choice(broad_)\n",
    "    resolution = random.choice(res_)\n",
    "    # Randomly Select a M3db simulation\n",
    "    sim_num = random.randint(0,len(ampls_filter)-1)\n",
    "    sim_vals = ampls_filter.iloc[sim_num]\n",
    "    # Now add all of the lines where the amplitudes are normalized to Halpha... \n",
    "    ampls = [sim_vals['h1']/sim_vals['h1'], sim_vals['n1']/sim_vals['h1'], sim_vals['n2']/sim_vals['h1'], sim_vals['s1']/sim_vals['h1'], sim_vals['s2']/sim_vals['h1']]\n",
    "    spectrum_axis, spectrum = Spectrum(lines, fit_function, ampls, velocity, broadening, filter_, resolution, SNR).create_spectrum()\n",
    "    # We now add noise\n",
    "    # We now must get the indices for the axis at our limits -- necessary because we sample over resolution space\n",
    "    min_ = np.argmin(np.abs(np.array(spectrum_axis)-14400))  # min wavenumber is 14400\n",
    "    max_ = np.argmin(np.abs(np.array(spectrum_axis)-15700))  # max wavenumber is 15700 \n",
    "    spectrum = spectrum[min_:max_] \n",
    "    spectrum_axis = spectrum_axis[min_:max_]\n",
    "    # Normalize Spectrum Values by the maximum value\n",
    "    spec_max = np.max(spectrum)\n",
    "    spectrum = [spec_/spec_max for spec_ in spectrum]\n",
    "    # Gather information to make Fits file\n",
    "    col1 = fits.Column(name='Wavenumber', format='E', array=spectrum_axis)\n",
    "    col2 = fits.Column(name='Flux', format='E', array=spectrum)\n",
    "    cols = fits.ColDefs([col1, col2])\n",
    "    hdu = fits.BinTableHDU.from_columns(cols)\n",
    "    # Header info\n",
    "    hdr = fits.Header()\n",
    "    hdr['OBSERVER'] = 'Carter Rhea'\n",
    "    hdr['COMMENT'] = \"Synthetic Spectrum Number: %i\"%spec_ct\n",
    "    hdr['TIME'] =  datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    hdr['VELOCITY'] = velocity\n",
    "    hdr['BROADEN'] = broadening\n",
    "    hdr['THETA'] = theta\n",
    "    hdr['SIM'] = 'BOND'\n",
    "    hdr['SIM_NUM'] = sim_num\n",
    "    empty_primary = fits.PrimaryHDU(header=hdr)\n",
    "    hdul = fits.HDUList([empty_primary, hdu])\n",
    "    hdul.writeto(output_dir+'Spectrum_%i.fits'%spec_ct, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
